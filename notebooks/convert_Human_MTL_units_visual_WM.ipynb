{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.072264700Z",
     "start_time": "2023-09-05T07:16:42.643776800Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from os import listdir, PathLike, path\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from hdmf.backends.hdf5 import H5DataIO\n",
    "from pynwb import NWBFile, TimeSeries\n",
    "from pynwb.behavior import BehavioralEvents\n",
    "from pynwb.file import Subject\n",
    "from pynwb.ecephys import ElectrodeGroup, ElectricalSeries, LFP\n",
    "from os.path import join\n",
    "import nixio\n",
    "import regex as re\n",
    "from usz_neuro_conversion.common import (\n",
    "    SessionContext,\n",
    "    NixContext,\n",
    "    get_metadata_row,\n",
    "    read_nix,\n",
    "    get_date,\n",
    "    write_nwb,\n",
    "    standardize_sex,\n",
    "    find_nix_files,\n",
    "    get_micro_dir,\n",
    "    get_matlab_matrix, get_matlab_matrix_scalars_ragged\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.096269600Z",
     "start_time": "2023-09-05T07:16:48.070263300Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_nix_to_nwb(subject: int, session: int) -> SessionContext:\n",
    "    global info\n",
    "    info = None\n",
    "    ctx = create_context(subject, session)\n",
    "    print(\"Writing subject\")\n",
    "    write_subject(ctx)\n",
    "    print(\"Writing electrode columns\")\n",
    "    add_electrode_columns(ctx)\n",
    "    print(\"Writing iEEG electrodes\")\n",
    "    ieeg_electrode_group = write_ieeg_electrodes(ctx)\n",
    "    print(\"Writing iEEG measurements\")\n",
    "    write_ieeg_measurements(ctx)\n",
    "    print(\"Writing behavior\")\n",
    "    write_behavior(ctx)\n",
    "    print(\"Writing events\")\n",
    "    write_events(ctx)\n",
    "    print(\"Writing trial data\")\n",
    "    write_trial_data(ctx)\n",
    "    print(\"Writing waveforms\")\n",
    "    write_waveforms(ctx, ieeg_electrode_group)\n",
    "    print(\"Writing LFP\")\n",
    "    write_lfp(ctx)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.130448500Z",
     "start_time": "2023-09-05T07:16:48.087268600Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_context(subject: int, session: int) -> SessionContext:\n",
    "    nix_context = NixContext(subject, session, project=\"Human_MTL_units_visual_WM\")\n",
    "    nix = read_nix(nix_context)\n",
    "    general = nix.sections[\"General\"]\n",
    "    nwb = NWBFile(\n",
    "        session_description=\"Running experiment as described in the the experiment description\",\n",
    "        identifier=f\"Human_MTL_units_visual_WM_subject{subject:02}_session{session:02}\",\n",
    "        session_start_time=get_date(nix_context),\n",
    "        lab=general.props[\"Recording location\"].values[0],\n",
    "        institution=\"Universitätsspital Zürich, 8091 Zurich, Switzerland\",  # Broken UTF-8 in file\n",
    "        related_publications=_get_related_publications(nix),\n",
    "        experimenter=\"Boran, Ece\",\n",
    "        experiment_description=_get_experiment(nix),\n",
    "        keywords=[\n",
    "            \"Visual\",\n",
    "            \"Spatial\",\n",
    "            \"Neural decoding\",\n",
    "            \"Hippocampus\",\n",
    "            \"Entorhinal cortex\",\n",
    "        ],\n",
    "    )\n",
    "    return nix_context.to_session_context(nix, nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.152236700Z",
     "start_time": "2023-09-05T07:16:48.102265100Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_experiment(nix: nixio.File) -> str:\n",
    "    task = nix.sections[\"Task\"].props\n",
    "    task_name = task[\"Task name\"].values[0]\n",
    "    # Broken UTF-8 in file\n",
    "    task_desc = \"The task is a change detection task designed to examine the visual working memory of subjects. In each trial, arrays of colored squares were presented and had to be memorized. The number of squares determined the set size: 1, 2, 4 or 6. There was a total 192 trials per session. Each trial started with a warning signal (0.4 s) that was a red fixation dot. The fixation dot was then changed to black (0.4 – 0.5 s, jittered). A memory array (encoding period, 0.8 s) was followed by a delay (retention interval, 0.9 s). After the delay, a test array was shown (2 s) followed by a jittered inter-trial interval of 1.3 to 2.3 s. The participants indicated by button press (“Same” or “Different”, forced choice) whether the test array differed from the memory array. If the arrays differed, only one square changed in colour, but all squares remained on the same location. The fixation dot was visible on the screen during the whole trial period. Eight different colours were used for the memory and test array (yellow, red, green, blue, magenta, cyan, grey, black). Before starting the sessions, participants conducted trial runs in a practice session to learn the task. In this session we verified if participants were colour-blind and could discriminate all colours. Practice sessions were repeated until the participant understood the task and was able to follow the pace of the trials.\"\n",
    "    task_url = \"https://www.neurobs.com/ex_files/expt_view?id=285&tree_item_url=klaver12.exp&item_id=klaver12.exp\"  # Found online\n",
    "    return (\n",
    "        f\"Task Name: {task_name}\\nTask Description: {task_desc}\\nTask URL: {task_url}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.187840500Z",
     "start_time": "2023-09-05T07:16:48.152236700Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_related_publications(_nix: nixio.File) -> List[str]:\n",
    "    dois = [\"https://doi.org/10.1016/j.neuroimage.2022.119123\"]  # Found online\n",
    "    return [doi.strip() for doi in dois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.235339600Z",
     "start_time": "2023-09-05T07:16:48.189840300Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_subject(ctx: SessionContext):\n",
    "    metadata = get_metadata_row(ctx.to_nix_context())\n",
    "    age = metadata[\"Age\"]\n",
    "    sex = metadata[\"Sex\"]\n",
    "    ctx.nwb.subject = Subject(\n",
    "        subject_id=f\"{ctx.subject:02}\",\n",
    "        age=f\"P{int(age)}Y\",\n",
    "        description=_get_subject_description(ctx),\n",
    "        species=\"Homo sapiens\",\n",
    "        sex=standardize_sex(sex),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.235339600Z",
     "start_time": "2023-09-05T07:16:48.204085300Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_subject_description(ctx: SessionContext) -> str:\n",
    "    metadata = get_metadata_row(ctx.to_nix_context())\n",
    "    subject = ctx.nix.sections[\"Subject\"].props\n",
    "    handedness = metadata[\"Handedness\"]\n",
    "    pathology = metadata[\"Pathology\"]\n",
    "    implanted_electrodes = subject[\"Implanted electrodes\"].values[0]\n",
    "    electrodes_in_soz = metadata[\"Electrodes in seizure onset zone (SOZ)\"]\n",
    "    return f\"Handedness: {handedness}\\nPathology: {pathology}\\nImplanted electrodes: {implanted_electrodes}\\nElectrodes in seizure onset zone (SOZ): {electrodes_in_soz}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.286354100Z",
     "start_time": "2023-09-05T07:16:48.235339600Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_electrode_columns(ctx: SessionContext):\n",
    "    ctx.nwb.add_electrode_column(\n",
    "        name=\"label\",\n",
    "        description=\"Channel label referenced by other data arrays\",\n",
    "    )\n",
    "    ctx.nwb.add_electrode_column(\n",
    "        name=\"is_inside_soz\",\n",
    "        description=\"Indicates whether the electrode is inside the seizure onset zone (SOZ)\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.333006400Z",
     "start_time": "2023-09-05T07:16:48.286354100Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_session_data(ctx: SessionContext) -> nixio.Block:\n",
    "    return ctx.nix.blocks[f\"Data_Subject_{ctx.subject:02}_Session_{ctx.session:02}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.364523Z",
     "start_time": "2023-09-05T07:16:48.301980700Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_ieeg_electrodes(ctx: SessionContext) -> ElectrodeGroup:\n",
    "    nwb = ctx.nwb\n",
    "\n",
    "    device = nwb.create_device(\n",
    "        name=\"ATLAS Neurophysiology System\",\n",
    "        manufacturer=\"Neuralynx, Inc.\",\n",
    "        description=\"iEEG recording system\",\n",
    "    )\n",
    "\n",
    "    # create an electrode group for this group\n",
    "    electrode_group = nwb.create_electrode_group(\n",
    "        name=\"ieeg\",\n",
    "        description=f\"iEEG electrodes\",\n",
    "        device=device,\n",
    "        location=\"Intracranial\",\n",
    "    )\n",
    "\n",
    "    electrodes = _get_ieeg_electrodes(ctx)\n",
    "    electrodes.apply(\n",
    "        lambda row: _add_row_to_ieeg_electrodes(nwb, electrode_group, row), axis=1\n",
    "    )\n",
    "    return electrode_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.388522100Z",
     "start_time": "2023-09-05T07:16:48.326993100Z"
    }
   },
   "outputs": [],
   "source": [
    "VISUAL_TASK_ELECTRODES = pd.read_csv(\n",
    "    \"../out/metadata/visual_task_electrodes.tsv\", sep=\"\\t\"\n",
    ")\n",
    "VISUAL_TASK_ELECTRODES[\"anatomical_location\"] = VISUAL_TASK_ELECTRODES[\n",
    "    \"anatomical_location\"\n",
    "].fillna(\"unspecific\")\n",
    "VISUAL_TASK_ELECTRODES = VISUAL_TASK_ELECTRODES.astype(\n",
    "    {\"label\": \"string\", \"anatomical_location\": \"string\", \"inside_soz\": \"bool\"}\n",
    ")\n",
    "\n",
    "\n",
    "def _get_ieeg_electrodes(ctx: SessionContext) -> pd.DataFrame:\n",
    "    # only keep the current subject\n",
    "    df = VISUAL_TASK_ELECTRODES.loc[\n",
    "        VISUAL_TASK_ELECTRODES[\"participant\"] == ctx.subject\n",
    "        ]\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.420710100Z",
     "start_time": "2023-09-05T07:16:48.376525800Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_labels(ctx: SessionContext) -> List[str]:\n",
    "    electrodes = _get_ieeg_electrodes(ctx)\n",
    "    return electrodes[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.424708Z",
     "start_time": "2023-09-05T07:16:48.401525900Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_labels_including_lfp(ctx: SessionContext) -> List[str]:\n",
    "    file = _find_micro_data_files(ctx)[ctx.subject][ctx.session][1]\n",
    "    labels = []\n",
    "    with h5py.File(file, 'r') as file:\n",
    "        for refs in file.get(\"data/label\"):\n",
    "            for ref in refs:\n",
    "                labels.append(file[ref][:])\n",
    "    labels = [[char[0] for char in label] for label in labels]\n",
    "    # int to utf-8\n",
    "    labels = [\"\".join(map(chr, label)) for label in labels]\n",
    "    # trim leading 'u'\n",
    "    labels = [label[1:] for label in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.445238900Z",
     "start_time": "2023-09-05T07:16:48.422711600Z"
    }
   },
   "outputs": [],
   "source": [
    "def _add_row_to_ieeg_electrodes(\n",
    "        nwb: NWBFile, electrode_group: ElectrodeGroup, row: pd.Series\n",
    "):\n",
    "    # Got MNI map: +X is right, +Y is anterior, +Z is superior according to <https://kathleenhupfeld.com/mni-template-coordinate-systems/>\n",
    "    # But need NWB: +X is posterior, +Y is inferior, +Z is right according to <https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile.add_electrode>\n",
    "    nwb.add_electrode(\n",
    "        group=electrode_group,\n",
    "        label=row[\"label\"],\n",
    "        location=row[\"anatomical_location\"],\n",
    "        reference=\"Common intracranial reference\",\n",
    "        is_inside_soz=row[\"inside_soz\"],\n",
    "        x=-row[\"y\"] if not np.isnan(row[\"y\"]) else None,\n",
    "        y=-row[\"z\"] if not np.isnan(row[\"z\"]) else None,\n",
    "        z=row[\"x\"] if not np.isnan(row[\"x\"]) else None,\n",
    "        filtering=\"Passband, 1 to 8000 Hz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.486056400Z",
     "start_time": "2023-09-05T07:16:48.437724100Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_ieeg_measurements(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    ieeg_electrode_indices = list(range(_get_ieeg_electrode_count(ctx)))\n",
    "    nwb.create_electrode_table_region(\n",
    "        region=ieeg_electrode_indices,  # reference row indices 0 to N-1\n",
    "        description=\"ieeg electrodes\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.486056400Z",
     "start_time": "2023-09-05T07:16:48.456242100Z"
    }
   },
   "outputs": [],
   "source": [
    "_IEEG_RE = re.compile(r\"iEEG_Data_Trial_(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.525729400Z",
     "start_time": "2023-09-05T07:16:48.486056400Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_count(ctx: SessionContext) -> int:\n",
    "    return len(_get_ieeg_electrode_labels(ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.552533200Z",
     "start_time": "2023-09-05T07:16:48.501684500Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_events(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    session = _get_session_data(ctx)\n",
    "    tags = session.groups[\"Trial events single tags spike times\"].tags\n",
    "    tags_by_trial = [(_EVENT_RE.findall(tag.name)[0], tag.position) for tag in tags]\n",
    "    events = [\n",
    "        (int(trial_number) - 1, name, position[0])\n",
    "        for (name, trial_number), position in tags_by_trial\n",
    "        if name != \"Response\"\n",
    "    ]\n",
    "    events.sort(key=lambda x: x[0])\n",
    "    offset = _get_time_offset(ctx)\n",
    "    last_trial = events[-1][0]\n",
    "    events = [\n",
    "        (name, time - offset + _get_total_time_before(ctx, trial_number))\n",
    "        for trial_number, name, time in events\n",
    "    ]\n",
    "    end = _get_total_time_after(ctx, last_trial)\n",
    "    events.append((\"END\", end))\n",
    "\n",
    "    for (name, start), (_, end) in zip(events, events[1:]):\n",
    "        nwb.add_epoch(\n",
    "            start_time=start,\n",
    "            stop_time=end,\n",
    "            tags=name,\n",
    "            timeseries=_get_main_time_series(ctx),\n",
    "        )\n",
    "        assert start < end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.552533200Z",
     "start_time": "2023-09-05T07:16:48.537517800Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_main_time_series(ctx: SessionContext) -> List[TimeSeries]:\n",
    "    nwb = ctx.nwb\n",
    "    return [nwb.processing[\"behavior\"].get(\"BehavioralEvents.response\").get_timeseries(\"response\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.599020700Z",
     "start_time": "2023-09-05T07:16:48.552533200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Event_Retention_Trial_183_Spike_Times\n",
    "_EVENT_RE = re.compile(r\"Event_([a-zA-Z]+)_.*Trial_(\\d+)_Spike_Times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.621023300Z",
     "start_time": "2023-09-05T07:16:48.568171600Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_trial_data(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    nwb.add_trial_column(\n",
    "        name=\"set_size\",\n",
    "        description=\"Number of colored squares in array presented during encoding period. Either 1, 2, 4, or 6.\",\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"solution\",\n",
    "        description='The correct answer to the question \"Was the array presented during the test the same as the one presented during the encoding period?\"',\n",
    "    )\n",
    "\n",
    "    nix = ctx.nix\n",
    "    trials = nix.sections[\"Session\"].sections[\"Trial properties\"].sections\n",
    "    for trial in trials:\n",
    "        trial = trial.props\n",
    "        trial_number = int(trial[\"Trial number\"].values[0]) - 1\n",
    "        start_time = _get_total_time_before(ctx, trial_number)\n",
    "        stop_time = _get_total_time_after(ctx, trial_number)\n",
    "        assert start_time < stop_time\n",
    "        nwb.add_trial(\n",
    "            id=trial_number,\n",
    "            start_time=start_time,\n",
    "            stop_time=stop_time,\n",
    "            set_size=int(trial[\"Set size\"].values[0]),\n",
    "            solution=trial[\"Match\"].values[0] == 1,\n",
    "            timeseries=_get_main_time_series(ctx),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.625023400Z",
     "start_time": "2023-09-05T07:16:48.599020700Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_behavior(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    behavior_module = nwb.create_processing_module(\n",
    "        name=\"behavior\", description=\"Data for all trials in this session.\"\n",
    "    )\n",
    "    nix = ctx.nix\n",
    "    trials = nix.sections[\"Session\"].sections[\"Trial properties\"].sections\n",
    "    offset = _get_time_offset(ctx)\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    for trial in trials:\n",
    "        trial_number = int(trial[\"Trial number\"]) - 1\n",
    "        trial = trial.props\n",
    "        data.append(trial[\"Response\"].values[0] == 1)\n",
    "        time = trial[\"Response time\"].values[0] - offset + _get_total_time_before(ctx, trial_number)\n",
    "        timestamps.append(time)\n",
    "\n",
    "    time_series = TimeSeries(\n",
    "        name=\"response\",\n",
    "        data=data,\n",
    "        timestamps=timestamps,\n",
    "        description='The participant\\'s answer to the question \"Was the array presented during the test the same as the one presented during the encoding period?\"',\n",
    "        unit=\"n/a\",  # Might as well use https://github.com/rly/ndx-events, but it's not built-in...\n",
    "        continuity=\"instantaneous\",\n",
    "    )\n",
    "\n",
    "    behavioral_events = BehavioralEvents(\n",
    "        name=f\"BehavioralEvents.response\", time_series=time_series\n",
    "    )\n",
    "\n",
    "    behavior_module.add(behavioral_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.670783Z",
     "start_time": "2023-09-05T07:16:48.620021Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_waveforms(ctx: SessionContext, ieeg_electrode_group: ElectrodeGroup):\n",
    "    nwb = ctx.nwb\n",
    "    session = _get_session_data(ctx)\n",
    "    waveforms = session.groups[\"Spike waveforms\"].data_arrays\n",
    "    spike_times = session.groups[\"Spike times\"].data_arrays\n",
    "    if len(waveforms) == 0:\n",
    "        assert len(spike_times) == 0\n",
    "        return\n",
    "\n",
    "    waveforms = [\n",
    "        (_WAVEFORM_RE.findall(waveform.name)[0], waveform) for waveform in waveforms\n",
    "    ]\n",
    "    waveforms = [\n",
    "        (int(unit), electrode, channel, values)\n",
    "        for (unit, electrode, channel), values in waveforms\n",
    "    ]\n",
    "    waveforms.sort(key=lambda x: x[0])\n",
    "\n",
    "    spike_times = [\n",
    "        (_SPIKE_TIMES_RE.findall(spike_time.name)[0], spike_time[:])\n",
    "        for spike_time in spike_times\n",
    "    ]\n",
    "    unit_to_trial_to_spike_times = {}\n",
    "    for (unit, electrode, channel, trial), values in spike_times:\n",
    "        unit_to_trial_to_spike_times.setdefault(int(unit), {})[trial] = (\n",
    "            electrode,\n",
    "            channel,\n",
    "            values,\n",
    "        )\n",
    "\n",
    "    nwb.add_unit_column(\n",
    "        name=\"offset\",\n",
    "        description=\"The offset in seconds of the first waveform voltage relative to the spike event\",\n",
    "    )\n",
    "    waveform_sampling_interval = session.groups[\"Spike waveforms\"].data_arrays[0].dimensions[1].sampling_interval\n",
    "    nwb.units.waveform_rate = 1.0 / waveform_sampling_interval\n",
    "    waveform_offset = session.groups[\"Spike waveforms\"].data_arrays[0].dimensions[1].offset\n",
    "\n",
    "    for unit, electrode, channel, waveform_voltages in waveforms:\n",
    "        trial_to_spike_times = unit_to_trial_to_spike_times[unit]\n",
    "\n",
    "        spike_times_for_trials = []\n",
    "        for trial, (electrode_, channel_, spike_times) in trial_to_spike_times.items():\n",
    "            assert electrode == electrode_\n",
    "            assert channel == channel_\n",
    "            spike_times_for_trials.append((trial, spike_times))\n",
    "        spike_times_for_trials.sort(key=lambda x: x[0])\n",
    "        spike_times_for_trials = [\n",
    "            spike_times for _, spike_times in spike_times_for_trials\n",
    "        ]\n",
    "        spike_times_for_trials = _untrialize_irregular_timestamps(\n",
    "            spike_times_for_trials, ctx\n",
    "        )\n",
    "\n",
    "        electrode_label = f\"{electrode}{channel}\"\n",
    "        electrode_index = _get_electrode_index(ctx, electrode_label)\n",
    "\n",
    "        means = [micro_volt * 1e-6 for micro_volt in waveform_voltages[:][0]]\n",
    "        sds = [micro_volt * 1e-6 for micro_volt in waveform_voltages[:][1]]\n",
    "\n",
    "        obs_intervals = _get_obs_intervals(ctx)\n",
    "        nwb.add_unit(\n",
    "            id=int(unit),\n",
    "            electrode_group=ieeg_electrode_group,\n",
    "            electrodes=[electrode_index],\n",
    "            waveform_mean=means,\n",
    "            waveform_sd=sds,\n",
    "            spike_times=spike_times_for_trials,\n",
    "            obs_intervals=obs_intervals,\n",
    "            offset=waveform_offset\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.685791900Z",
     "start_time": "2023-09-05T07:16:48.662822500Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_obs_intervals(ctx: SessionContext) -> List[Tuple[float, float]]:\n",
    "    trials = ctx.nix.sections[\"Session\"].sections[\"Trial properties\"].sections\n",
    "    return [(_get_total_time_before(ctx, i), _get_total_time_after(ctx, i)) for i in range(len(trials))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.729218700Z",
     "start_time": "2023-09-05T07:16:48.685791900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spike_Waveform_Unit_1_uAHL_2\n",
    "_WAVEFORM_RE = re.compile(r\"Spike_Waveform_Unit_(\\d+)_u([a-zA-Z]+)_(\\d+)\")\n",
    "# Spike_Times_Unit_36_uPHR_1_Trial_16\n",
    "_SPIKE_TIMES_RE = re.compile(r\"Spike_Times_Unit_(\\d+)_u([a-zA-Z]+)_(\\d+)_Trial_(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.731218600Z",
     "start_time": "2023-09-05T07:16:48.701425300Z"
    }
   },
   "outputs": [],
   "source": [
    "def _untrialize_irregular_timestamps(\n",
    "        timestamps: List[List[float]], ctx: SessionContext\n",
    ") -> List[float]:\n",
    "    offset = _get_time_offset(ctx)\n",
    "    untrialized = []\n",
    "    for trial, times in enumerate(timestamps):\n",
    "        times = [time - offset + _get_total_time_before(ctx, trial) for time in times]\n",
    "        untrialized.extend(times)\n",
    "    return untrialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.753739700Z",
     "start_time": "2023-09-05T07:16:48.723207100Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_electrode_index(ctx: SessionContext, electrode: str) -> int:\n",
    "    nwb = ctx.nwb\n",
    "    index = next(\n",
    "        index\n",
    "        for index, electrodes in enumerate(nwb.electrodes[\"label\"][:])\n",
    "        if electrode in electrodes\n",
    "    )\n",
    "    return nwb.electrodes[\"id\"][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.754738600Z",
     "start_time": "2023-09-05T07:16:48.737214900Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_time_offset(_ctx: SessionContext) -> float:\n",
    "    return -1.7  # taken from looking at event data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.802227100Z",
     "start_time": "2023-09-05T07:16:48.757736900Z"
    }
   },
   "outputs": [],
   "source": [
    "def _get_total_time_before(ctx: SessionContext, trial: int):\n",
    "    info = get_matlab_trial_info(ctx)\n",
    "    min_offset = info.loc[info.TrialNumber == 1, \"TimeStartSampleS\"].values[\n",
    "        0]  # Needed because LFPs start earlier than the first trial\n",
    "    start_time = info.loc[info.TrialNumber == 1, \"TimeStartTimestamp\"].values[0]\n",
    "    end_time = info.loc[info.TrialNumber == trial + 1, \"TimeStartTimestamp\"].values[0]\n",
    "    return (end_time - start_time) / 1e6 + min_offset\n",
    "\n",
    "\n",
    "def _get_total_time_after(ctx: SessionContext, trial: int):\n",
    "    info = get_matlab_trial_info(ctx)\n",
    "    min_offset = info.loc[info.TrialNumber == 1, \"TimeStartSampleS\"].values[0]\n",
    "    start_time = info.loc[info.TrialNumber == 1, \"TimeStartTimestamp\"].values[0]\n",
    "    end_time = info.loc[info.TrialNumber == trial + 1, \"TimeStopTimestamp\"].values[0]\n",
    "    return (end_time - start_time) / 1e6 + min_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.829214800Z",
     "start_time": "2023-09-05T07:16:48.786602Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_lfp(ctx: SessionContext):\n",
    "    if not path.exists(_find_micro_data_files(ctx)[ctx.subject][ctx.session][1]):\n",
    "        print(\"No LFP data found\")\n",
    "        return\n",
    "    nwb = ctx.nwb\n",
    "\n",
    "    supported_labels = _get_ieeg_electrode_labels(ctx)\n",
    "    lfp_labels = _get_ieeg_electrode_labels_including_lfp(ctx)\n",
    "    supported_indices = []\n",
    "    unsupported_indices = []\n",
    "\n",
    "    for i, label in enumerate(lfp_labels):\n",
    "        if label in supported_labels:\n",
    "            supported_indices.append(supported_labels.index(label))\n",
    "        else:\n",
    "            unsupported_indices.append(i)\n",
    "    assert len(supported_indices) > 0\n",
    "\n",
    "    print(\"Reading LFP data\")\n",
    "    micro_data = prepare_micro_data(ctx)\n",
    "    print(\"Manipulating LFP data\")\n",
    "    ieeg_electrode_indices = supported_indices\n",
    "    ieeg_table_region = nwb.create_electrode_table_region(\n",
    "        region=ieeg_electrode_indices,\n",
    "        description=\"ieeg electrodes\",\n",
    "    )\n",
    "\n",
    "    data = micro_data.matrix\n",
    "    assert data.shape[1] == len(lfp_labels)\n",
    "    if len(unsupported_indices) > 0:\n",
    "        data = np.delete(data, unsupported_indices, axis=1)\n",
    "    assert data.shape[1] == len(supported_indices)\n",
    "\n",
    "    compressed_data = H5DataIO(\n",
    "        data=data,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "    if micro_data.trial_info.Part.max() == 1:\n",
    "        electrical_series = ElectricalSeries(\n",
    "            name=\"ecephys.lfp\",\n",
    "            description=\"iEEG data\",\n",
    "            data=compressed_data,\n",
    "            electrodes=ieeg_table_region,\n",
    "            starting_time=3.125e-05,\n",
    "            rate=0.00025,\n",
    "        )\n",
    "    else:\n",
    "        timestamps = micro_data.timestamps_per_trial\n",
    "        compressed_timestamps = H5DataIO(\n",
    "            data=timestamps,\n",
    "            compression=\"gzip\",\n",
    "        )\n",
    "        electrical_series = ElectricalSeries(\n",
    "            name=\"ecephys.lfp\",\n",
    "            description=\"iEEG data\",\n",
    "            data=compressed_data,\n",
    "            electrodes=ieeg_table_region,\n",
    "            timestamps=compressed_timestamps,\n",
    "        )\n",
    "\n",
    "    lfp = LFP(electrical_series)\n",
    "    ecephys_module = nwb.create_processing_module(\n",
    "        name=\"ecephys\", description=\"processed extracellular electrophysiology data\"\n",
    "    )\n",
    "    ecephys_module.add(lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T08:29:23.311662Z",
     "start_time": "2023-09-05T08:29:23.176206400Z"
    }
   },
   "outputs": [],
   "source": [
    "def _find_micro_data_files(ctx: SessionContext) -> Dict[int, Dict[int, Dict[int, PathLike]]]:\n",
    "    dir = get_micro_dir(ctx)\n",
    "    micro_files = {}\n",
    "    for file in listdir(dir):\n",
    "        match = MATLAB_RE.match(file)\n",
    "        file = file.replace(\".csv\", \".mat\")\n",
    "        if match:\n",
    "            subject, session, part = map(int, match.groups())\n",
    "            if subject not in CORRECTED_PATIENT:\n",
    "                continue\n",
    "            subject = CORRECTED_PATIENT[subject]\n",
    "            if subject not in micro_files:\n",
    "                micro_files[subject] = {}\n",
    "            if session not in micro_files[subject]:\n",
    "                micro_files[subject][session] = {}\n",
    "            micro_files[subject][session][part] = join(dir, file)\n",
    "            if subject == 10 and session == 1:\n",
    "                part_two_file = file.replace(\"Part_01\", \"Part_02\")\n",
    "                micro_files[subject][session][2] = join(dir, part_two_file)\n",
    "    return micro_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.852486900Z",
     "start_time": "2023-09-05T07:16:48.837213400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Created manually because the provided list was wrong...\n",
    "CORRECTED_PATIENT = {\n",
    "    13: 1,\n",
    "    34: 2,\n",
    "    29: 3,\n",
    "    30: 4,\n",
    "    37: 5,\n",
    "    35: 6,\n",
    "    38: 7,\n",
    "    40: 8,\n",
    "    19: 9,\n",
    "    23: 10,\n",
    "    41: 11,\n",
    "    28: 12,\n",
    "    22: 13,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T08:22:57.064342500Z",
     "start_time": "2023-09-05T08:22:56.957555Z"
    }
   },
   "outputs": [],
   "source": [
    "info = None\n",
    "\n",
    "\n",
    "def get_matlab_trial_info(ctx: SessionContext) -> pd.DataFrame:\n",
    "    global info\n",
    "    if info is not None:\n",
    "        return info\n",
    "    micro_files = _find_micro_data_files(ctx)\n",
    "    files = micro_files[ctx.subject]\n",
    "    reference_file = files[ctx.session][1]  # all csvs are called part 1\n",
    "    csv_name = reference_file.replace(\".mat\", \".csv\")\n",
    "    with open(csv_name, \"r\") as file:\n",
    "        info = pd.read_csv(file, sep=\",\")\n",
    "    return info\n",
    "\n",
    "\n",
    "def get_trial_indices(ctx: SessionContext) -> List[int]:\n",
    "    micro_info = get_matlab_trial_info(ctx)\n",
    "    # Source: https://stackoverflow.com/a/17215844\n",
    "    x = micro_info.loc[:, \"Session\"] == ctx.session\n",
    "    return x[x].index.values\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class MicroData:\n",
    "    matrix: np.ndarray\n",
    "    trial_info: pd.DataFrame\n",
    "    timestamps_per_trial: np.ndarray\n",
    "\n",
    "\n",
    "def prepare_micro_data(ctx: SessionContext) -> MicroData:\n",
    "    micro_files = _find_micro_data_files(ctx)\n",
    "    files = micro_files[ctx.subject][ctx.session]\n",
    "\n",
    "    file = files[1]\n",
    "\n",
    "    with h5py.File(file, 'r') as file:\n",
    "        ref = file.get(\"data/trial\")[0][0]\n",
    "\n",
    "        matrix = np.array(file[ref][:])\n",
    "        assert abs(matrix[-1, -1]) > 1e-6\n",
    "\n",
    "        trial_info = get_matlab_trial_info(ctx)\n",
    "\n",
    "        times = None\n",
    "\n",
    "        if len(files) > 1:\n",
    "            assert len(files) == 2\n",
    "\n",
    "            times_ref = file.get(\"data/time\")[0][0]\n",
    "            times = file[times_ref][:][:, 0]\n",
    "            assert times[-1] > 1\n",
    "            assert matrix.shape[0] == times.shape[0]\n",
    "\n",
    "            with h5py.File(files[2], 'r') as file:\n",
    "                ref = file.get(\"data/trial\")[0][0]\n",
    "                matrix = np.concatenate((matrix, np.array(file[ref][:])))\n",
    "                times_ref = file.get(\"data/time\")[0][0]\n",
    "\n",
    "                last_stop_timestamp_of_part_one = trial_info.loc[(trial_info.Part == 1), \"TimeStopTimestamp\"].max()\n",
    "                first_start_timestamp_of_part_two = trial_info.loc[(trial_info.Part == 2), \"TimeStartTimestamp\"].min()\n",
    "                offset = first_start_timestamp_of_part_two - last_stop_timestamp_of_part_one\n",
    "                offset = offset / 1e6  # mus to s\n",
    "                lfp_to_measurement_lag = 2.868  # Copied by hand, first TimeStartSampleS of part 2\n",
    "                offset -= lfp_to_measurement_lag\n",
    "\n",
    "                second_part_times = file[times_ref][:][:, 0] + offset\n",
    "                times = np.concatenate((times, second_part_times))\n",
    "                assert matrix.shape[0] == times.shape[0]\n",
    "                assert abs(matrix[-1, -1]) > 1e-6\n",
    "                assert times[-1] > 1\n",
    "\n",
    "        return MicroData(\n",
    "            matrix=matrix,\n",
    "            trial_info=trial_info,\n",
    "            timestamps_per_trial=times\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T07:16:48.903734Z",
     "start_time": "2023-09-05T07:16:48.884485500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Micro_Intervals_Patient_19_Session_01_Part_01_Interval_0_NaN_s\n",
    "MATLAB_RE = re.compile(r\"Micro_Intervals_Patient_(\\d+)_Session_(\\d+)_Part_(\\d+)_Interval_0_NaN_s.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-05T08:33:58.744706600Z",
     "start_time": "2023-09-05T08:29:30.857493600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "(2013312,)\n",
      "(3142464,)\n",
      "(5155776,)\n",
      "Manipulating LFP data\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    context = convert_nix_to_nwb(10, 1)\n",
    "    write_nwb(context)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting subject 4 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 5 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 6 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 7 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 8 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 8 session 2\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 9 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 10 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Failed to convert 10 1\n",
      "Cannot get attribute 'dtype' of data. Data is not valid.\n",
      "Converting subject 11 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "No LFP data found\n",
      "Done\n",
      "Converting subject 12 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Converting subject 12 session 2\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "No LFP data found\n",
      "Done\n",
      "Converting subject 13 session 1\n",
      "Writing subject\n",
      "Writing electrode columns\n",
      "Writing iEEG electrodes\n",
      "Writing iEEG measurements\n",
      "Writing behavior\n",
      "Writing events\n",
      "Writing trial data\n",
      "Writing waveforms\n",
      "Writing LFP\n",
      "Reading LFP data\n",
      "Manipulating LFP data\n",
      "Done\n",
      "Everything done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    project = \"Human_MTL_units_visual_WM\"\n",
    "    for subject, sessions in find_nix_files(project).items():\n",
    "        for session, _ in sessions.items():\n",
    "            if subject < 4:\n",
    "                continue\n",
    "            if subject == 1 and session == 1:\n",
    "                continue\n",
    "            print(f\"Converting subject {subject} session {session}\")\n",
    "            try:\n",
    "                context = convert_nix_to_nwb(subject, session)\n",
    "                write_nwb(context)\n",
    "                print(\"Done\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {subject} {session}\")\n",
    "                print(e)\n",
    "    print(\"Everything done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

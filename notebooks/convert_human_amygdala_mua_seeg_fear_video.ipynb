{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hdmf.backends.hdf5 import H5DataIO\n",
    "from pynwb import NWBFile, TimeSeries\n",
    "from pynwb.file import Subject\n",
    "from pynwb.ecephys import ElectricalSeries, ElectrodeGroup, LFP\n",
    "from pynwb.behavior import BehavioralEvents\n",
    "import nixio\n",
    "import regex as re\n",
    "from nwbwidgets import nwb2widget\n",
    "from usz_neuro_conversion.common import (\n",
    "    SessionContext,\n",
    "    NixContext,\n",
    "    get_metadata_row,\n",
    "    read_nix,\n",
    "    get_date,\n",
    "    write_nwb,\n",
    "    read_nwb,\n",
    "    standardize_sex,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_nix_to_nwb(subject: int, session: int) -> SessionContext:\n",
    "    ctx = create_context(subject, session)\n",
    "    write_subject(ctx)\n",
    "    ieeg_electrode_group = write_ieeg_electrodes(ctx)\n",
    "    write_ieeg_measurements(ctx)\n",
    "    write_trial_data(ctx)\n",
    "    write_behavior(ctx)\n",
    "    write_events(ctx)\n",
    "    write_waveforms(ctx, ieeg_electrode_group)\n",
    "    return ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(subject: int, session: int) -> SessionContext:\n",
    "    nix_context = NixContext(\n",
    "        subject, session, project=\"Human_Amygdala_MUA_sEEG_FearVideo\"\n",
    "    )\n",
    "    nix = read_nix(nix_context)\n",
    "    general = nix.sections[\"General\"]\n",
    "    nwb = NWBFile(\n",
    "        session_description=\"Running experiment as described in the the experiment description\",\n",
    "        identifier=f\"Human_Amygdala_MUA_sEEG_FearVideo_subject{subject:02}_session{session:02}\",\n",
    "        session_start_time=get_date(nix_context),\n",
    "        lab=general.props[\"Recording location\"].values[0],\n",
    "        institution=\"Universitätsspital Zürich, 8091 Zurich, Switzerland\",  # Broken UTF-8 in file\n",
    "        related_publications=_get_related_publications(nix),\n",
    "        experimenter=\"Fedele, Tommaso\",  # TODO is this right?\n",
    "        experiment_description=_get_experiment(nix),\n",
    "        keywords=[\n",
    "            \"EEG\",\n",
    "            \"iEEG\",\n",
    "            \"LFP\",\n",
    "            \"Epilepsy\",\n",
    "            \"Memory\",\n",
    "            \"Sternberg\",\n",
    "            \"Verbal\",\n",
    "        ],  # TODO\n",
    "    )\n",
    "    return nix_context.to_session_context(nix, nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_experiment(nix: nixio.File) -> str:\n",
    "    task = nix.sections[\"Task\"].props\n",
    "    task_name = task[\"Task name\"].values[0]\n",
    "    # Broken UTF-8 in file\n",
    "    task_desc = \"We used a paradigm comprising of a series of dynamic videos, which has been already validated in previous clinical investigations (Schacher et al., 2006). The videos were all silent and consisted of dynamic fearful faces and dynamic neutral landscapes, presented in an alternating order, in a block design. The paradigm included eight blocks of 75 short video clips (2–3 s) of fearful faces (aversive condition) and nine blocks of 72 short video clips (2–3 s) of neutral landscapes (neutral condition). Each block lasted 24 s in total, and contained short video clips without any intermission between consecutive videos. Video clips of fearful faces were extracted from thriller and horror movies and contained faces of actors showing fear, without being violent or aggressive. Video clips of neutral landscapes were chosen as a control condition, and were matched to the duration of the fearful faces videos (2–3 s). They included domestic landscapes which are posited to have a low emotional content and visual properties comparable to the emotional videos (Schacher et al., 2006). All videos were only included once. A panel of psychologists had evaluated the stimuli to ensure that they are suitable for the patients and that they do not include any episodes of violence or aggression (Schacher et al., 2006). In particular, we started with a set of 120 videos of fearful faces and reduced that to 72, by excluding videos where: (a) the actor’s face was not continuously visible (b) fear was not clearly recognized on the actor’s face (c) no other emotion was displayed (e.g. anger/surprise) and (d) the display of fear was intense. During electrophysiological recordings the videos were presented to the patients via a laptop screen, while during the fMRI scan they were presented through a tilted overhead mirror. In both cases, patients were instructed to pay attention to the videos and focus on the eyes of the actors during the clips containing faces. For the electrophysiological recordings, blocks were separated by a repeated baseline of 2 s taken from a neutral condition.\"\n",
    "    task_url = task[\"Task URL\"].values[0]\n",
    "    return (\n",
    "        f\"Task Name: {task_name}\\nTask Description: {task_desc}\\nTask URL: {task_url}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_related_publications(nix: nixio.File) -> List[str]:\n",
    "    related_publications = (\n",
    "        nix.sections[\"General\"].sections[\"Related publications\"].props\n",
    "    )\n",
    "    dois = related_publications[\"Publication DOI\"].values\n",
    "    return [doi.strip() for doi in dois]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_subject(ctx: SessionContext):\n",
    "    metadata = get_metadata_row(ctx.to_nix_context())\n",
    "    age = metadata[\"Age\"]\n",
    "    sex = metadata[\"Sex\"]\n",
    "    ctx.nwb.subject = Subject(\n",
    "        subject_id=f\"{ctx.subject:02}\",\n",
    "        age=f\"P{int(age)}Y\",\n",
    "        description=_get_subject_description(ctx),\n",
    "        species=\"Homo sapiens\",\n",
    "        sex=standardize_sex(sex),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_subject_description(ctx: SessionContext) -> str:\n",
    "    metadata = get_metadata_row(ctx.to_nix_context())\n",
    "    subject = ctx.nix.sections[\"Subject\"].props\n",
    "    handedness = metadata[\"Handedness\"]\n",
    "    pathology = metadata[\"Pathology\"]\n",
    "    depth_electrodes = subject[\"Depth electrodes\"].values[0]\n",
    "    electrodes_in_soz = metadata[\"Electrodes in seizure onset zone (SOZ)\"]\n",
    "    return f\"Handedness: {handedness}\\nPathology: {pathology}\\nDepth electrodes: {depth_electrodes}\\nElectrodes in seizure onset zone (SOZ): {electrodes_in_soz}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_session_data(ctx: SessionContext) -> nixio.Block:\n",
    "    return ctx.nix.blocks[f\"Data_Subject_{ctx.subject:02}_Session_{ctx.session:02}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ieeg_electrodes(ctx: SessionContext) -> ElectrodeGroup:\n",
    "    nwb = ctx.nwb\n",
    "\n",
    "    device = nwb.create_device(\n",
    "        name=\"ATLAS Neurophysiology System\",\n",
    "        manufacturer=\"Neuralynx, Inc.\",\n",
    "        description=\"iEEG recording system\",\n",
    "    )\n",
    "\n",
    "    # create an electrode group for this group\n",
    "    electrode_group = nwb.create_electrode_group(\n",
    "        name=\"ieeg\",\n",
    "        description=f\"iEEG electrodes\",\n",
    "        device=device,\n",
    "        location=\"Intracranial\",\n",
    "    )\n",
    "\n",
    "    electrodes = _get_ieeg_electrodes(ctx)\n",
    "    electrodes.apply(\n",
    "        lambda row: _add_row_to_ieeg_electrodes(nwb, electrode_group, row), axis=1\n",
    "    )\n",
    "    return electrode_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ieeg_electrodes(ctx: SessionContext) -> pd.DataFrame:\n",
    "    labels = _get_ieeg_electrode_labels(ctx)\n",
    "    locations = _get_ieeg_electrode_locations(ctx)\n",
    "    locations_array = np.ndarray(locations.shape)\n",
    "    locations.read_direct(locations_array)\n",
    "    df = pd.DataFrame(locations_array, columns=[\"x\", \"y\", \"z\"])\n",
    "    df.insert(0, \"label\", labels)\n",
    "    return df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_labels(ctx: SessionContext) -> List[str]:\n",
    "    return (\n",
    "        _get_session_data(ctx)\n",
    "        .groups[\"iEEG electrode information\"]\n",
    "        .data_arrays[\"iEEG_Electrode_Manual_Entry\"]\n",
    "        .dimensions[0]\n",
    "        .labels\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_locations(ctx: SessionContext) -> nixio.DataArray:\n",
    "    return (\n",
    "        _get_session_data(ctx)\n",
    "        .groups[\"iEEG electrode information\"]\n",
    "        .data_arrays[\"iEEG_Electrode_MNI_Coordinates\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _add_row_to_ieeg_electrodes(\n",
    "        nwb: NWBFile, electrode_group: ElectrodeGroup, row: pd.Series\n",
    "):\n",
    "    # Got MNI map: +X is right, +Y is anterior, +Z is superior according to <https://kathleenhupfeld.com/mni-template-coordinate-systems/>\n",
    "    # But need NWB: +X is posterior, +Y is inferior, +Z is right according to <https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile.add_electrode>\n",
    "    # TODO: Got \"Inside/Outside SOZ as well\"\n",
    "    nwb.add_electrode(\n",
    "        group=electrode_group,\n",
    "        location=row[\"label\"],\n",
    "        reference=\"Common intracranial reference\",\n",
    "        x=-row[\"y\"],\n",
    "        y=-row[\"z\"],\n",
    "        z=row[\"x\"],\n",
    "        filtering=\"Passband, 0.5 to 1000 Hz\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_ieeg_measurements(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    ieeg_electrode_indices = list(range(_get_ieeg_electrode_count(ctx)))\n",
    "    ieeg_table_region = nwb.create_electrode_table_region(\n",
    "        region=ieeg_electrode_indices,  # reference row indices 0 to N-1\n",
    "        description=\"ieeg electrodes\",\n",
    "    )\n",
    "    trials = _get_session_data(ctx).groups[\"iEEG data\"].data_arrays\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    duration = _get_trial_duration(ctx)\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    for trial in trials:\n",
    "        trial_number = int(_IEEG_RE.findall(trial.name)[0])\n",
    "        data.append(trial[:])\n",
    "        sampling_interval = trial.dimensions[1].sampling_interval\n",
    "        times = [\n",
    "            i * sampling_interval - offset + trial_number * duration\n",
    "            for i in range(trial.shape[1])\n",
    "        ]\n",
    "        timestamps.extend(times)\n",
    "    data = np.concatenate(data, axis=1).transpose()\n",
    "\n",
    "    compressed_data = H5DataIO(\n",
    "        data=data,\n",
    "        compression=\"gzip\",\n",
    "    )\n",
    "    electrical_series = ElectricalSeries(\n",
    "        name=\"ecephys.ieeg\",\n",
    "        description=\"iEEG data\",\n",
    "        data=compressed_data,\n",
    "        electrodes=ieeg_table_region,\n",
    "        timestamps=timestamps,\n",
    "    )\n",
    "    lfp = LFP(electrical_series)\n",
    "    ecephys_module = nwb.create_processing_module(\n",
    "        name=\"ecephys\", description=\"processed extracellular electrophysiology data\"\n",
    "    )\n",
    "    ecephys_module.add(lfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "_IEEG_RE = re.compile(r\"iEEG_Data_Trial_(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_ieeg_electrode_count(ctx: SessionContext) -> int:\n",
    "    return len(_get_ieeg_electrode_labels(ctx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_events(ctx: SessionContext):\n",
    "    nwb = ctx.nwb\n",
    "    session = _get_session_data(ctx)\n",
    "    tags = session.groups[\n",
    "        \"Trial events single tags spike times\"\n",
    "    ].tags  # same as EEG and iEEG in this case\n",
    "    tags_by_trial = [(_EVENT_RE.findall(tag.name)[0], tag.position) for tag in tags]\n",
    "    events = [\n",
    "        (int(trial), name, position[0])\n",
    "        for (name, trial), position in tags_by_trial\n",
    "        if name != \"Response\"\n",
    "    ]\n",
    "    events.sort(key=lambda x: x[0])\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    duration = _get_trial_duration(ctx)\n",
    "    events = [\n",
    "        (name, time - offset + trial_number * duration)\n",
    "        for trial_number, name, time in events\n",
    "    ]\n",
    "    events.append((\"END\", len(events) * duration))\n",
    "\n",
    "    for (name, start), (_, end) in zip(events, events[1:]):\n",
    "        nwb.add_epoch(\n",
    "            start_time=start,\n",
    "            stop_time=end,\n",
    "            tags=name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_trial_data(ctx: SessionContext):\n",
    "    # TODO\n",
    "    nwb = ctx.nwb\n",
    "    nwb.add_trial_column(name=\"trial_number\", description=\"The trial number\")\n",
    "    nwb.add_trial_column(\n",
    "        name=\"set_size\",\n",
    "        description=\"Number of letters shown during encoding period (4, 6, or 8 letters)\",\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"probe_letter\",\n",
    "        description=\"The letter presented to the participant during the retrieval period\",\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"response\",\n",
    "        description='The participant\\'s answer to the question \"Was the letter at hand present in the encoding set?\"',\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"response_time\",\n",
    "        description=\"The time at which the participant responded during the retrieval period\",\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"solution\",\n",
    "        description='The solution to the question \"Was the letter at hand present in the encoding set?\"',\n",
    "    )\n",
    "    nwb.add_trial_column(\n",
    "        name=\"artifact\",\n",
    "        description=\"Whether the trial data was marked as an artifact by the experimenter\",\n",
    "    )\n",
    "\n",
    "    nix = ctx.nix\n",
    "    trials = nix.sections[\"Session\"].sections[\"Trial properties\"].sections\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    duration = _get_trial_duration(ctx)\n",
    "    for trial in trials:\n",
    "        trial = trial.props\n",
    "        trial_number = int(trial[\"Trial number\"].values[0])\n",
    "        start_time = offset + trial_number * duration\n",
    "        stop_time = start_time + duration\n",
    "        response_time = trial[\"Response time\"].values[0] + start_time\n",
    "        # See https://gin.g-node.org/USZ_NCH/Human_MTL_units_scalp_EEG_and_iEEG_verbal_WM/issues/2#issuecomment-3729\n",
    "        response = str(trial[\"Response\"].values[0])[1] == 1\n",
    "        solution = int(trial[\"Match\"].values[0]) == 1\n",
    "        nwb.add_trial(\n",
    "            start_time=start_time,\n",
    "            stop_time=stop_time,\n",
    "            trial_number=int(trial[\"Trial number\"].values[0]),\n",
    "            set_size=int(trial[\"Set size\"].values[0]),\n",
    "            probe_letter=str(trial[\"Probe letter\"].values[0]),\n",
    "            response=response,\n",
    "            response_time=response_time,\n",
    "            solution=solution,\n",
    "            artifact=bool(trial[\"Artifact\"].values[0]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_behavior(ctx: SessionContext):\n",
    "    # TODO\n",
    "    nwb = ctx.nwb\n",
    "    behavior_module = nwb.create_processing_module(\n",
    "        name=\"behavior\", description=\"Data for all trials in this session.\"\n",
    "    )\n",
    "    nix = ctx.nix\n",
    "    trials = nix.sections[\"Session\"].sections[\"Trial properties\"].sections\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    duration = _get_trial_duration(ctx)\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    for trial in trials:\n",
    "        trial_number = int(trial[\"Trial number\"])\n",
    "        trial = trial.props\n",
    "        # See https://gin.g-node.org/USZ_NCH/Human_MTL_units_scalp_EEG_and_iEEG_verbal_WM/issues/2#issuecomment-3729\n",
    "        data.append(str(trial[\"Response\"].values[0])[1] == 1)\n",
    "        time = trial[\"Response time\"].values[0] - offset + trial_number * duration\n",
    "        timestamps.append(time)\n",
    "        # Have to do this because everything after the response is fake time inbetween trials because NWB requires all trials to be on one long stretch\n",
    "        nwb.add_invalid_time_interval(\n",
    "            start_time=time,\n",
    "            stop_time=(trial_number + 1.0) * duration,\n",
    "        )\n",
    "\n",
    "    time_series = TimeSeries(\n",
    "        name=\"response\",\n",
    "        data=data,\n",
    "        timestamps=timestamps,\n",
    "        description='The participant\\'s answer to the question \"Was the letter at hand present in the encoding set?\"',\n",
    "        unit=\"n/a\",  # Might as well use https://github.com/rly/ndx-events, but it's not built-in...\n",
    "        continuity=\"instantaneous\",\n",
    "    )\n",
    "\n",
    "    behavioral_events = BehavioralEvents(\n",
    "        name=f\"BehavioralEvents.response\", time_series=time_series\n",
    "    )\n",
    "\n",
    "    behavior_module.add(behavioral_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EVENT_RE = re.compile(r\"Event_([a-zA-Z]+)_.*Trial_(\\d\\d)_.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_waveforms(ctx: SessionContext, ieeg_electrode_group: ElectrodeGroup):\n",
    "    nwb = ctx.nwb\n",
    "    session = _get_session_data(ctx)\n",
    "    waveforms = session.groups[\"Spike waveforms\"].data_arrays\n",
    "    spike_times = session.groups[\"Spike times\"].data_arrays\n",
    "    waveforms = [\n",
    "        (_WAVEFORM_RE.findall(waveform.name)[0], waveform) for waveform in waveforms\n",
    "    ]\n",
    "    spike_times = [\n",
    "        (_SPIKE_TIMES_RE.findall(spike_time.name)[0], spike_time[:])\n",
    "        for spike_time in spike_times\n",
    "    ]\n",
    "    unit_to_waveform = {\n",
    "        int(unit): (electrode, channel, values)\n",
    "        for ((unit, electrode, channel), values) in waveforms\n",
    "    }\n",
    "    unit_to_trial_to_spike_times = {}\n",
    "    for (unit, electrode, channel, trial), values in spike_times:\n",
    "        unit_to_trial_to_spike_times.setdefault(int(unit), {})[trial] = (\n",
    "            electrode,\n",
    "            channel,\n",
    "            values,\n",
    "        )\n",
    "    for unit, (electrode, channel, waveform) in unit_to_waveform.items():\n",
    "        trial_to_spike_times = unit_to_trial_to_spike_times[unit]\n",
    "\n",
    "        spike_times_for_trials = []\n",
    "        for trial, (electrode_, channel_, spike_times) in trial_to_spike_times.items():\n",
    "            assert electrode == electrode_\n",
    "            assert channel == channel_\n",
    "            spike_times_for_trials.append((trial, spike_times))\n",
    "        spike_times_for_trials.sort(key=lambda x: x[0])\n",
    "        spike_times_for_trials = [\n",
    "            spike_times for _, spike_times in spike_times_for_trials\n",
    "        ]\n",
    "        spike_times_for_trials = _untrialize_irregular_timestamps(\n",
    "            spike_times_for_trials, ctx\n",
    "        )\n",
    "\n",
    "        electrode_label = f\"m{electrode}{channel}\"\n",
    "        electrode_index = _get_electrode_index(ctx, electrode_label)\n",
    "        data_point_count = waveform.shape[1]\n",
    "        sample_interval = waveform.dimensions[1].sampling_interval\n",
    "        offset = waveform.dimensions[1].offset\n",
    "        min_time = 0 + offset\n",
    "        max_time = min_time + data_point_count * sample_interval\n",
    "        data = waveform[:]\n",
    "        nwb.add_unit(\n",
    "            id=int(unit),\n",
    "            electrode_group=ieeg_electrode_group,\n",
    "            electrodes=[electrode_index],\n",
    "            waveform_mean=data[0],\n",
    "            waveform_sd=data[1],\n",
    "            obs_intervals=[\n",
    "                (time + min_time, time + max_time) for time in spike_times_for_trials\n",
    "            ],\n",
    "            spike_times=spike_times_for_trials,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike_Waveform_Unit_1_uAHL_2\n",
    "_WAVEFORM_RE = re.compile(r\"Spike_Waveform_Unit_(\\d+)_u([a-zA-Z]+)_(\\d+)\")\n",
    "# Spike_Times_Unit_36_uPHR_1_Trial_16\n",
    "_SPIKE_TIMES_RE = re.compile(r\"Spike_Times_Unit_(\\d+)_u([a-zA-Z]+)_(\\d+)_Trial_(\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _untrialize_irregular_timestamps(\n",
    "        timestamps: List[List[float]], ctx: SessionContext\n",
    ") -> List[float]:\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    duration = _get_trial_duration(ctx)\n",
    "    untrialized = []\n",
    "    for trial, times in enumerate(timestamps):\n",
    "        times = [time - offset + trial * duration for time in times]\n",
    "        untrialized.extend(times)\n",
    "    return untrialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_electrode_index(ctx: SessionContext, electrode: str) -> int:\n",
    "    return ctx.nwb.electrodes[\"location\"][:].index(electrode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_trial_duration(ctx: SessionContext) -> float:\n",
    "    offset = _get_measurement_offset(ctx)\n",
    "    return ctx.nix.sections[\"Session\"].props[\"Trial duration\"].values[0] - offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_measurement_offset(ctx: SessionContext) -> float:\n",
    "    return (\n",
    "        _get_session_data(ctx)\n",
    "        .groups[\"Scalp EEG data\"]\n",
    "        .data_arrays[0]\n",
    "        .dimensions[1]\n",
    "        .offset\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    context = convert_nix_to_nwb(1, 1)\n",
    "    write_nwb(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    nwb = read_nwb(context.subject, context.session)\n",
    "    nwb2widget(nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test\n"
     ]
    }
   ],
   "source": [
    "print(\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DELETE ANYTHING PYCHARM GENERATES AFTER THIS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
